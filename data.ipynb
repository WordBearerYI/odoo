{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "img_dir = \"/data/colposcopy/colposcopy\"\n",
    "\n",
    "type_1_train = glob(os.path.join(img_dir,\"train*\",\"Type_1\",\"*.jpg\"))\n",
    "type_2_train = glob(os.path.join(img_dir,\"train*\",\"Type_2\",\"*.jpg\"))\n",
    "type_3_train = glob(os.path.join(img_dir,\"train*\",\"Type_3\",\"*.jpg\"))\n",
    "\n",
    "img_test   = glob(os.path.join(img_dir,\"test\",\"*.jpg\"))\n",
    "img_test_wo_answer = glob(os.path.join(img_dir,\"test_stg2\",\"*.jpg\"))\n",
    "f = open(os.path.join(img_dir,\"solution_stg1_release.csv\"))\n",
    "type_dict = {}\n",
    "\n",
    "cont = f.readlines()\n",
    "for i in range(1, len(cont)):\n",
    "    line = cont[i].rstrip('\\n')\n",
    "    ctype = line.split(',').index('1')\n",
    "#    print(i,ctype)\n",
    "    type_dict[i] = ctype\n",
    "f.close()\n",
    "\n",
    "print(\"training num:\",len(type_1_train),len(type_2_train),len(type_3_train))\n",
    "print(\"test num (with answer):\",len(img_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fosun_dir = os.path.join(img_dir,\"extra\",\"yindaojing\")\n",
    "extra_pic = glob(os.path.join(img_fosun_dir,\"*\",\"caporg*.jpg\"))\n",
    "\n",
    "patient_dict = {}\n",
    "def process_dir(cur_dir):\n",
    "    cur_patient = cur_dir.split('/')[-2]\n",
    "    cur_img = cur_dir.split('/')[-1]\n",
    "    if cur_patient in patient_dict:\n",
    "        patient_dict[cur_patient].append(cur_img) \n",
    "    else:\n",
    "        patient_dict[cur_patient] = []\n",
    "    return cur_patient+'::'+cur_img\n",
    "\n",
    "extra_valid = list(map(lambda x:process_dir(x),extra_pic))\n",
    "print (len(patient_dict))\n",
    "susm = 0\n",
    "for ii in patient_dict:\n",
    "    susm += len(patient_dict[ii])\n",
    "print(susm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "def get_img_from_path(num_pat,num_pic):\n",
    "    return cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][num_pic]))\n",
    "def plot_img_from_path(num_pat,num_pic):\n",
    "    plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][num_pic]))))\n",
    "def plot_imgs_from_path(num_pat):\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    num_pic = len(patient_dict[str(num_pat)])\n",
    "    if num_pic<3:\n",
    "        for i in range(0,num_pic): \n",
    "            plt.subplot(100+10*num_pic+i+1)\n",
    "            plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][i]))))  \n",
    "    else:\n",
    "        for i in range(0,4): \n",
    "            plt.subplot(100+10*num_pic+i+1)\n",
    "            plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][i]))))\n",
    "            \n",
    "def plot_with_color(img,channel):\n",
    "    size = img.shape\n",
    "    zeros = np.zeros(size,dtype=\"uint8\")\n",
    "    if channel == 'r' or channel == 0:\n",
    "        return cv2.merge([zeros,zeros,img])\n",
    "    elif channel == 'g' or channel == 1:\n",
    "        return cv2.merge([zeros,img,zeros])\n",
    "    else:\n",
    "        return cv2.merge([img,zeros,zeros])\n",
    "    \n",
    "def channel_split(image,opencv=True):\n",
    "    if opencv == True:\n",
    "        b_channel = image[:,:,0]\n",
    "        g_channel = image[:,:,1]\n",
    "        \n",
    "        r_channel = image[:,:,2]\n",
    "    else:\n",
    "        r_channel = image[:,:,0]\n",
    "        g_channel = image[:,:,1]\n",
    "        b_channel = image[:,:,2]\n",
    "    return r_channel,g_channel,b_channel\n",
    "\n",
    "pat = 60\n",
    "plot_imgs_from_path(pat)\n",
    "img_1 = get_img_from_path(pat,1)\n",
    "img_2 = get_img_from_path(pat,2)\n",
    "img_3 = get_img_from_path(pat,3)\n",
    "r_channel,g_channel,b_channel = channel_split(img_1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(cvt(plot_with_color(r_channel,0)))\n",
    "plt.subplot(132)\n",
    "plt.imshow(cvt(plot_with_color(g_channel,1)))\n",
    "plt.subplot(133)\n",
    "plt.imshow(cvt(plot_with_color(b_channel,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for remove spetral reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_3\n",
    "r_c = img[:,:,2]\n",
    "g_c = img[:,:,1]\n",
    "b_c = img[:,:,0]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "_,r_thres = cv2.threshold(r_c, 210, 255, cv2.THRESH_BINARY)\n",
    "_,g_thres = cv2.threshold(g_c, 208, 255, cv2.THRESH_BINARY)\n",
    "_,b_thres = cv2.threshold(b_c, 206, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(r_thres)\n",
    "plt.subplot(142)\n",
    "plt.imshow(g_thres)\n",
    "plt.subplot(143)\n",
    "plt.imshow(b_thres)\n",
    "plt.subplot(144)\n",
    "\n",
    "mixed = r_thres & b_thres & g_thres\n",
    "kernel_dilate = np.ones((18, 18), np.uint8)\n",
    "mask = cv2.dilate(mixed,kernel_dilate)\n",
    "plt.imshow(mask)\n",
    "\n",
    "dst = cv2.inpaint(img,mask,14,cv2.INPAINT_TELEA)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(cvt(img_3))\n",
    "plt.subplot(122)\n",
    "plt.imshow(cvt(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = type_1_train[2]\n",
    "i1 = cvt(cv2.imread(i1))\n",
    "i2 = type_1_train[24]\n",
    "i2 = cvt(cv2.imread(i2))\n",
    "i3 = type_1_train[211]\n",
    "i3 = cvt(cv2.imread(i3))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(i1)\n",
    "plt.subplot(132)\n",
    "plt.imshow(i2)\n",
    "plt.subplot(133)\n",
    "plt.imshow(i3)\n",
    "\n",
    "print(i1.shape,i2.shape,i3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image file path from its id and type   \n",
    "    \"\"\"\n",
    "    if image_type == \"Type_1\" or \\\n",
    "        image_type == \"Type_2\" or \\\n",
    "        image_type == \"Type_3\":\n",
    "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
    "    elif image_type == \"Test\":\n",
    "        data_path = TEST_DATA\n",
    "    elif image_type == \"AType_1\" or \\\n",
    "          image_type == \"AType_2\" or \\\n",
    "          image_type == \"AType_3\":\n",
    "        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    ext = 'jpg'\n",
    "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
    "\n",
    "def get_image_data(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxHist(hist):\n",
    "    maxArea = (0, 0, 0)\n",
    "    height = []\n",
    "    position = []\n",
    "    for i in range(len(hist)):\n",
    "        if (len(height) == 0):\n",
    "            if (hist[i] > 0):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "        else: \n",
    "            if (hist[i] > height[-1]):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "            elif (hist[i] < height[-1]):\n",
    "                while (height[-1] > hist[i]):\n",
    "                    maxHeight = height.pop()\n",
    "                    area = maxHeight * (i-position[-1])\n",
    "                    if (area > maxArea[0]):\n",
    "                        maxArea = (area, position[-1], i)\n",
    "                    last_position = position.pop()\n",
    "                    if (len(height) == 0):\n",
    "                        break\n",
    "                position.append(last_position)\n",
    "                if (len(height) == 0):\n",
    "                    height.append(hist[i])\n",
    "                elif(height[-1] < hist[i]):\n",
    "                    height.append(hist[i])\n",
    "                else:\n",
    "                    position.pop()    \n",
    "    while (len(height) > 0):\n",
    "        maxHeight = height.pop()\n",
    "        last_position = position.pop()\n",
    "        area =  maxHeight * (len(hist) - last_position)\n",
    "        if (area > maxArea[0]):\n",
    "            maxArea = (area, len(hist), last_position)\n",
    "    return maxArea\n",
    "            \n",
    "\n",
    "def maxRect(img):\n",
    "    maxArea = (0, 0, 0)\n",
    "    addMat = np.zeros(img.shape)\n",
    "    for r in range(img.shape[0]):\n",
    "        if r == 0:\n",
    "            addMat[r] = img[r]\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "        else:\n",
    "            addMat[r] = img[r] + addMat[r-1]\n",
    "            addMat[r][img[r] == 0] *= 0\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "    return (int(maxArea[3]+1-maxArea[0]/abs(maxArea[1]-maxArea[2])), maxArea[2], maxArea[3], maxArea[1], maxArea[0])\n",
    "\n",
    "def cropCircle(img):\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    img = cv2.resize(img, dsize=tile_size)\n",
    "            \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY);\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    _, contours, _ = cv2.findContours(thresh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    main_contour = sorted(contours, key = cv2.contourArea, reverse = True)[0]\n",
    "            \n",
    "    ff = np.zeros((gray.shape[0],gray.shape[1]), 'uint8') \n",
    "    cv2.drawContours(ff, main_contour, -1, 1, 15)\n",
    "    ff_mask = np.zeros((gray.shape[0]+2,gray.shape[1]+2), 'uint8')\n",
    "    cv2.floodFill(ff, ff_mask, (int(gray.shape[1]/2), int(gray.shape[0]/2)), 1)\n",
    "    \n",
    "    rect = maxRect(ff)\n",
    "    rectangle = [min(rect[0],rect[2]), max(rect[0],rect[2]), min(rect[1],rect[3]), max(rect[1],rect[3])]\n",
    "    img_crop = img[rectangle[0]:rectangle[1], rectangle[2]:rectangle[3]]\n",
    "    cv2.rectangle(ff,(min(rect[1],rect[3]),min(rect[0],rect[2])),(max(rect[1],rect[3]),max(rect[0],rect[2])),3,2)\n",
    "    \n",
    "    return [img_crop, rectangle, tile_size]\n",
    "\n",
    "def Ra_space(img, Ra_ratio, a_threshold):\n",
    "    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    Ra = np.zeros((w*h, 2))\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            R = math.sqrt((w/2-i)*(w/2-i) + (h/2-j)*(h/2-j))\n",
    "            Ra[i*h+j, 0] = R\n",
    "            Ra[i*h+j, 1] = min(imgLab[i][j][1], a_threshold)\n",
    "            \n",
    "    Ra[:,0] /= max(Ra[:,0])\n",
    "    Ra[:,0] *= Ra_ratio\n",
    "    Ra[:,1] /= max(Ra[:,1])\n",
    "\n",
    "    return Ra\n",
    "\n",
    "def get_and_crop_image(image_id, image_type):\n",
    "    img = get_image_data(image_id, image_type)\n",
    "    initial_shape = img.shape\n",
    "    [img, rectangle_cropCircle, tile_size] = cropCircle(img)\n",
    "    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    Ra = Ra_space(imgLab, 1.0, 150)\n",
    "    a_channel = np.reshape(Ra[:,1], (w,h))\n",
    "    \n",
    "    g = mixture.GaussianMixture(n_components = 2, covariance_type = 'diag', random_state = 0, init_params = 'kmeans')\n",
    "    image_array_sample = shuffle(Ra, random_state=0)[:1000]\n",
    "    g.fit(image_array_sample)\n",
    "    labels = g.predict(Ra)\n",
    "    labels += 1 # Add 1 to avoid labeling as 0 since regionprops ignores the 0-label.\n",
    "    \n",
    "    # The cluster that has the highest a-mean is selected.\n",
    "    labels_2D = np.reshape(labels, (w,h))\n",
    "    gg_labels_regions = measure.regionprops(labels_2D, intensity_image = a_channel)\n",
    "    gg_intensity = [prop.mean_intensity for prop in gg_labels_regions]\n",
    "    cervix_cluster = gg_intensity.index(max(gg_intensity)) + 1\n",
    "\n",
    "    mask = np.zeros((w * h,1),'uint8')\n",
    "    mask[labels==cervix_cluster] = 255\n",
    "    mask_2D = np.reshape(mask, (w,h))\n",
    "\n",
    "    cc_labels = measure.label(mask_2D, background=0)\n",
    "    regions = measure.regionprops(cc_labels)\n",
    "    areas = [prop.area for prop in regions]\n",
    "\n",
    "    regions_label = [prop.label for prop in regions]\n",
    "    largestCC_label = regions_label[areas.index(max(areas))]\n",
    "    mask_largestCC = np.zeros((w,h),'uint8')\n",
    "    mask_largestCC[cc_labels==largestCC_label] = 255\n",
    "\n",
    "    img_masked = img.copy()\n",
    "    img_masked[mask_largestCC==0] = (0,0,0)\n",
    "    img_masked_gray = cv2.cvtColor(img_masked, cv2.COLOR_RGB2GRAY);\n",
    "            \n",
    "    _,thresh_mask = cv2.threshold(img_masked_gray,0,255,0)\n",
    "            \n",
    "    kernel = np.ones((11,11), np.uint8)\n",
    "    thresh_mask = cv2.dilate(thresh_mask, kernel, iterations = 1)\n",
    "    thresh_mask = cv2.erode(thresh_mask, kernel, iterations = 2)\n",
    "    _, contours_mask, _ = cv2.findContours(thresh_mask.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    main_contour = sorted(contours_mask, key = cv2.contourArea, reverse = True)[0]\n",
    "    cv2.drawContours(img, main_contour, -1, 255, 3)\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(main_contour)\n",
    "    \n",
    "    rectangle = [x+rectangle_cropCircle[2],\n",
    "                 y+rectangle_cropCircle[0],\n",
    "                 w,\n",
    "                 h,\n",
    "                 initial_shape[0],\n",
    "                 initial_shape[1],\n",
    "                 tile_size[0],\n",
    "                 tile_size[1]]\n",
    "\n",
    "    return [image_id, img, rectangle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_image_cropping(image_ids):\n",
    "    out = open('rectangles.csv', \"w\")\n",
    "    out.write(\"image_id,type,x,y,w,h,img_shp_0_init,img_shape1_init,img_shp_0,img_shp_1\\n\")\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    for cur_type in enumerate(types):\n",
    "        partial_get_and_crop = partial(get_and_crop_image, image_type = cur_type[1])    \n",
    "        ret = p.map(partial_get_and_crop, image_ids[cur_type[0]])\n",
    "        for i in range(len(ret)):\n",
    "            out.write(image_ids[type[0]][i])\n",
    "            out.write(',' + str(type[1]))\n",
    "            out.write(',' + str(ret[i][2][0]))\n",
    "            out.write(',' + str(ret[i][2][1]))\n",
    "            out.write(',' + str(ret[i][2][2]))\n",
    "            out.write(',' + str(ret[i][2][3]))\n",
    "            out.write(',' + str(ret[i][2][4]))\n",
    "            out.write(',' + str(ret[i][2][5]))\n",
    "            out.write(',' + str(ret[i][2][6]))\n",
    "            out.write(',' + str(ret[i][2][7]))\n",
    "            out.write('\\n')\n",
    "            img = get_image_data(image_ids[type[0]][i], type[1])\n",
    "            if(img.shape[0] > img.shape[1]):\n",
    "                tile_size = (int(img.shape[1]*256/img.shape[0]), 256)\n",
    "            else:\n",
    "                tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            cv2.rectangle(img,\n",
    "                          (ret[i][2][0], ret[i][2][1]), \n",
    "                          (ret[i][2][0]+ret[i][2][2], ret[i][2][1]+ret[i][2][3]),\n",
    "                          255,\n",
    "                          2)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        ret = []\n",
    "    out.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/data/colposcopy/colposcopy/train_stg2/Type_2/2845.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_1/5893.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_2/5892.jpg']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset,Sampler\n",
    "from torchvision import datasets,transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"/home/shiyi/gpu/gpu/\")\n",
    "sys.path.append(\"/home/shiyi/colposcopy/colposcopy/util\")\n",
    "img_dir = \"/data/colposcopy/colposcopy\"\n",
    "\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "corrupt_set  = set()\n",
    "types = [1,2,3]\n",
    "error = glob(os.path.join(img_dir,\"train*\",\"*\",\"2845.jpg\"))+ \\\n",
    "    glob(os.path.join(img_dir,\"train*\",\"*\",\"5893.jpg\"))+glob(os.path.join(img_dir,\"train*\",\"*\",\"5892.jpg\"))\n",
    "print(error)\n",
    "\n",
    "type_1_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_1\",\"*.jpg\")) if i not in error]\n",
    "type_2_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_2\",\"*.jpg\")) if i not in error]\n",
    "type_3_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_3\",\"*.jpg\")) if i not in error]\n",
    "\n",
    "type_data_train = [type_1_train,type_2_train,type_3_train]\n",
    "\n",
    "img_test   = glob(os.path.join(img_dir,\"test\",\"*.jpg\"))\n",
    "img_test_wo_answer = glob(os.path.join(img_dir,\"test_stg2\",\"*.jpg\"))\n",
    "test_path = os.path.join(img_dir,\"solution_stg1_release.csv\")\n",
    "\n",
    "def get_dict(file_path,imgs):\n",
    "    cur_dict = {}\n",
    "    f = open(file_path)\n",
    "    cont = f.readlines()[1:]\n",
    "    for i in range(len(cont)):\n",
    "        line = cont[i].rstrip('\\n')\n",
    "        cur_dict[i] = line.split(',').index('1')\n",
    "    f.close()\n",
    "    return cur_dict \n",
    "\n",
    "def collate_fn1(batch):\n",
    "    x = [item[0] for item in batch if item[0] is not None]\n",
    "    y = [item[1] for item in batch if item[0] is not None]\n",
    "    return x,y\n",
    "\n",
    "def sp_remove(img):\n",
    "    r_c = img[:,:,2]\n",
    "    g_c = img[:,:,1]\n",
    "    b_c = img[:,:,0]\n",
    "\n",
    "    _,r_thres = cv2.threshold(r_c, 210, 255, cv2.THRESH_BINARY)\n",
    "    _,g_thres = cv2.threshold(g_c, 208, 255, cv2.THRESH_BINARY)\n",
    "    _,b_thres = cv2.threshold(b_c, 206, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel_dilate = np.ones((18, 18), np.uint8)\n",
    "    mask = cv2.dilate(r_thres & b_thres & g_thres,kernel_dilate)\n",
    "    dst = cv2.inpaint(img,mask,14,cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "\n",
    "def crop(img):\n",
    "    return img\n",
    "\n",
    "def preprocess(img):\n",
    "    return crop(sp_remove(img))\n",
    "\n",
    "def cvt(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "class ColpoTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.type_dict = get_dict(test_path,img_test)\n",
    "    def __getitem__(self, index):\n",
    "        file_name = img_test[index]\n",
    "        x = cv2.imread(file_name)\n",
    "        if x is None:\n",
    "            return  None,None\n",
    "        #x = preprocess(x)\n",
    "        x =cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "        y =[0,0,0]\n",
    "        y [self.type_dict[index]-1] = 1\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return len(self.type_dict)\n",
    "    \n",
    "class ColpoTrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.Xy = []\n",
    "        for type_index in types:\n",
    "            for img_index in type_data_train[type_index-1]:\n",
    "                self.Xy.append((img_index,type_index))\n",
    "        self.x_data, self.y_data = zip(*self.Xy)\n",
    "        self.x_data = list(self.x_data)\n",
    "        self.y_data = list(self.y_data)\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.x_data[index]\n",
    "        x = cv2.imread(file_name)\n",
    "        if x is None:\n",
    "            return None,None\n",
    "        #x = preprocess(x)\n",
    "        x = cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "        y = [0,0,0]\n",
    "        y[self.y_data[index]-1] = 1\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,inchannel,outchannel,stride=1,shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.pre=nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,2,3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        \n",
    "        self.layer1=self._make_layer(64,64,3)\n",
    "        self.layer2=self._make_layer(64,128,4,stride=2)\n",
    "        self.layer3=self._make_layer(128,256,6,stride=2)\n",
    "        self.layer4=self._make_layer(256,512,3,stride=2)\n",
    "        self.fc=nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self,inchannel,outchannel,block_num,stride=1):\n",
    "        shortcut=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,1,stride,bias=False),\n",
    "            nn.BatchNorm2d(outchannel))\n",
    " \n",
    "        layers=[ ]\n",
    "        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))\n",
    "        \n",
    "        for i in range(1,block_num):\n",
    "            layers.append(ResidualBlock(outchannel,outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.pre(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=F.avg_pool2d(x,7)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Found 4 GPU(s)', 'only 2 gpu below threshold')\n",
      "Using GPU 1,0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:58<00:00,  1.48s/it]\n",
      "/root/anaconda2/lib/python2.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda2/lib/python2.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ResidualBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044091, Acc: 0.399903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:59<00:00,  1.64s/it]\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043675, Acc: 0.423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:13<00:00,  1.24s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044475, Acc: 0.390161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:56<00:00,  1.95s/it]\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043672, Acc: 0.423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:22<00:00,  1.20s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044469, Acc: 0.390039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:58<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043669, Acc: 0.423828\n",
      "set([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cuda = 1\n",
    "\n",
    "if cuda:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "    num_gpu = 2\n",
    "    set_gpu(num_gpu)\n",
    "\n",
    "if torch.cuda.is_available() and cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "batch_size_train = 16\n",
    "batch_size_test = 16\n",
    "colpoTrainDataset = ColpoTrainDataset()\n",
    "colpoTestDataset = ColpoTestDataset()\n",
    "\n",
    "train_loader = DataLoader(dataset=colpoTrainDataset,batch_size=batch_size_train,shuffle=True,num_workers = 2,collate_fn = collate_fn1)\n",
    "test_loader = DataLoader(dataset =colpoTestDataset,batch_size=batch_size_test,shuffle=True,num_workers = 2,collate_fn = collate_fn1)\n",
    "net=ResNet()\n",
    "\n",
    "if cuda:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    net = net.cuda()\n",
    "    \n",
    "criterion = nn.MultiLabelSoftMarginLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0\n",
    "    index = 0\n",
    "    total = 0\n",
    "    for batch_x,batch_y in tqdm(train_loader):\n",
    "        #print(batch_x,batch_y)\n",
    "        #print(torch.full((224,224,3), 0))\n",
    "        batch_x = Tensor(batch_x).permute([0,3,1,2])\n",
    "        batch_y = Tensor(batch_y)\n",
    "        total += batch_x.size()[0]\n",
    "        out = net(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(\"out\",out)\n",
    "        pred = torch.max(out,1)[1]\n",
    "        batch_y = torch.topk(batch_y, 1)[1].squeeze(1)\n",
    "        #print(\"pred\",pred,\"batch_y\",batch_y)\n",
    "        train_correct = (pred == batch_y).sum().item()\n",
    "        \n",
    "        #print(train_correct,\"correct of this batch of \", batch_x.size()[0])\n",
    "        train_acc += train_correct\n",
    "    torch.save(net, 'model.pth')    \n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss /total, train_acc/ total))\n",
    "\n",
    "    net.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    total = 0\n",
    "    for batch_x,batch_y in tqdm(test_loader):\n",
    "        batch_x = Tensor(batch_x).permute([0,3,1,2])\n",
    "        batch_y = Tensor(batch_y)\n",
    "        total += batch_x.size()[0]\n",
    "        #batch_x, batch_y = Variable(batch_x, volatile=True), Variable(batch_y, volatile=True)    \n",
    "        out = net(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        eval_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        batch_y = torch.topk(batch_y, 1)[1].squeeze(1)\n",
    "        num_correct = (pred == batch_y).sum().item()\n",
    "        eval_acc += num_correct\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / total, eval_acc / total))\n",
    "print(corrupt_set)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4018/4018 [10:45<00:00,  5.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "!rm /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
    "def test_net(save_file_path, net, img_dirs, transform =None, im_size=224, thresh=0.05):\n",
    "    \n",
    "    net = torch.load('model.pth')\n",
    "    test_all = img_test_wo_answer + img_test\n",
    "    with open(save_file_path,'w') as f:\n",
    "        #f.write(\"image_name,Type_1,Type_2,Type_3\\n\")\n",
    "        for idir in tqdm(test_all):\n",
    "            name = idir.split('/')[-1]\n",
    "            img = cv2.imread(idir)\n",
    "            if img is None:\n",
    "                label_ind = random.randint(0,3)\n",
    "                label_oh = [name,'0.0','0.0','0.0']\n",
    "                label_oh[label_ind] ='1.0'\n",
    "                \n",
    "            else:\n",
    "                if transform != None:\n",
    "                    img = transform(img)\n",
    "                img = cvt(cv2.resize(img,(im_size,im_size),interpolation=cv2.INTER_CUBIC))\n",
    "                x  = Tensor(img).permute([2,0,1]).unsqueeze(0)    \n",
    "                out = net(x)[0]\n",
    "                p = torch.nn.functional.softmax(out, dim=0)\n",
    "                # to calculate loss using probabilities you can do below \n",
    "                #print(p)\n",
    "                label_oh = [name]+map(lambda x: str(x.item()),p)\n",
    "            \n",
    "            label_oh = ','.join(label_oh)+\"\\n\"\n",
    "            #print (label_oh)\n",
    "            f.write(label_oh)\n",
    "\n",
    "test_net(\"/home/shiyi/colposcopy/colposcopy/odoo/submission.csv\", net, img_dir, transform =None, im_size=224, thresh=0.05)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.ipynb  GMM.ipynb  model.pth  README.md  rsa  submission.csv\n",
      "4018 /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
      "[master 32af987] tiredzzz\n",
      " 1 file changed, 1 insertion(+), 16 deletions(-)\n",
      "sy941021\n",
      "Counting objects: 3, done.\n",
      "Delta compression using up to 32 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 298 bytes | 0 bytes/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To git@github.com:WordBearerYI/odoo.git\n",
      "   4939ef5..32af987  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd /home/shiyi/colposcopy/colposcopy/odoo\n",
    "!ls\n",
    "!wc -l /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
    "\n",
    "!git add .\n",
    "!git commit -m \"tiredzzz\"\n",
    "!git push | echo WordBearerYI | echo sy941021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c intel-mobileodt-cervical-cancer-screening -f /home/shiyi/colposcopy/colposcopy/odoo/submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
