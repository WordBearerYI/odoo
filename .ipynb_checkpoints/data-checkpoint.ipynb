{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "img_dir = \"/data/colposcopy/colposcopy\"\n",
    "\n",
    "type_1_train = glob(os.path.join(img_dir,\"train*\",\"Type_1\",\"*.jpg\"))\n",
    "type_2_train = glob(os.path.join(img_dir,\"train*\",\"Type_2\",\"*.jpg\"))\n",
    "type_3_train = glob(os.path.join(img_dir,\"train*\",\"Type_3\",\"*.jpg\"))\n",
    "\n",
    "img_test   = glob(os.path.join(img_dir,\"test\",\"*.jpg\"))\n",
    "img_test_wo_answer = glob(os.path.join(img_dir,\"test_stg2\",\"*.jpg\"))\n",
    "f = open(os.path.join(img_dir,\"solution_stg1_release.csv\"))\n",
    "type_dict = {}\n",
    "\n",
    "cont = f.readlines()\n",
    "for i in range(1, len(cont)):\n",
    "    line = cont[i].rstrip('\\n')\n",
    "    ctype = line.split(',').index('1')\n",
    "#    print(i,ctype)\n",
    "    type_dict[i] = ctype\n",
    "f.close()\n",
    "\n",
    "print(\"training num:\",len(type_1_train),len(type_2_train),len(type_3_train))\n",
    "print(\"test num (with answer):\",len(img_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_fosun_dir = os.path.join(img_dir,\"extra\",\"yindaojing\")\n",
    "extra_pic = glob(os.path.join(img_fosun_dir,\"*\",\"caporg*.jpg\"))\n",
    "\n",
    "patient_dict = {}\n",
    "def process_dir(cur_dir):\n",
    "    cur_patient = cur_dir.split('/')[-2]\n",
    "    cur_img = cur_dir.split('/')[-1]\n",
    "    if cur_patient in patient_dict:\n",
    "        patient_dict[cur_patient].append(cur_img) \n",
    "    else:\n",
    "        patient_dict[cur_patient] = []\n",
    "    return cur_patient+'::'+cur_img\n",
    "\n",
    "extra_valid = list(map(lambda x:process_dir(x),extra_pic))\n",
    "print (len(patient_dict))\n",
    "susm = 0\n",
    "for ii in patient_dict:\n",
    "    susm += len(patient_dict[ii])\n",
    "print(susm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "def get_img_from_path(num_pat,num_pic):\n",
    "    return cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][num_pic]))\n",
    "def plot_img_from_path(num_pat,num_pic):\n",
    "    plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][num_pic]))))\n",
    "def plot_imgs_from_path(num_pat):\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    num_pic = len(patient_dict[str(num_pat)])\n",
    "    if num_pic<3:\n",
    "        for i in range(0,num_pic): \n",
    "            plt.subplot(100+10*num_pic+i+1)\n",
    "            plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][i]))))  \n",
    "    else:\n",
    "        for i in range(0,4): \n",
    "            plt.subplot(100+10*num_pic+i+1)\n",
    "            plt.imshow(cvt(cv2.imread(os.path.join(img_fosun_dir,str(num_pat),patient_dict[str(num_pat)][i]))))\n",
    "            \n",
    "def plot_with_color(img,channel):\n",
    "    size = img.shape\n",
    "    zeros = np.zeros(size,dtype=\"uint8\")\n",
    "    if channel == 'r' or channel == 0:\n",
    "        return cv2.merge([zeros,zeros,img])\n",
    "    elif channel == 'g' or channel == 1:\n",
    "        return cv2.merge([zeros,img,zeros])\n",
    "    else:\n",
    "        return cv2.merge([img,zeros,zeros])\n",
    "    \n",
    "def channel_split(image,opencv=True):\n",
    "    if opencv == True:\n",
    "        b_channel = image[:,:,0]\n",
    "        g_channel = image[:,:,1]\n",
    "        \n",
    "        r_channel = image[:,:,2]\n",
    "    else:\n",
    "        r_channel = image[:,:,0]\n",
    "        g_channel = image[:,:,1]\n",
    "        b_channel = image[:,:,2]\n",
    "    return r_channel,g_channel,b_channel\n",
    "\n",
    "pat = 60\n",
    "plot_imgs_from_path(pat)\n",
    "img_1 = get_img_from_path(pat,1)\n",
    "img_2 = get_img_from_path(pat,2)\n",
    "img_3 = get_img_from_path(pat,3)\n",
    "r_channel,g_channel,b_channel = channel_split(img_1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(cvt(plot_with_color(r_channel,0)))\n",
    "plt.subplot(132)\n",
    "plt.imshow(cvt(plot_with_color(g_channel,1)))\n",
    "plt.subplot(133)\n",
    "plt.imshow(cvt(plot_with_color(b_channel,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for remove spetral reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_3\n",
    "r_c = img[:,:,2]\n",
    "g_c = img[:,:,1]\n",
    "b_c = img[:,:,0]\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "_,r_thres = cv2.threshold(r_c, 210, 255, cv2.THRESH_BINARY)\n",
    "_,g_thres = cv2.threshold(g_c, 208, 255, cv2.THRESH_BINARY)\n",
    "_,b_thres = cv2.threshold(b_c, 206, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(r_thres)\n",
    "plt.subplot(142)\n",
    "plt.imshow(g_thres)\n",
    "plt.subplot(143)\n",
    "plt.imshow(b_thres)\n",
    "plt.subplot(144)\n",
    "\n",
    "mixed = r_thres & b_thres & g_thres\n",
    "kernel_dilate = np.ones((18, 18), np.uint8)\n",
    "mask = cv2.dilate(mixed,kernel_dilate)\n",
    "plt.imshow(mask)\n",
    "\n",
    "dst = cv2.inpaint(img,mask,14,cv2.INPAINT_TELEA)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(cvt(img_3))\n",
    "plt.subplot(122)\n",
    "plt.imshow(cvt(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = type_1_train[2]\n",
    "i1 = cvt(cv2.imread(i1))\n",
    "i2 = type_1_train[24]\n",
    "i2 = cvt(cv2.imread(i2))\n",
    "i3 = type_1_train[211]\n",
    "i3 = cvt(cv2.imread(i3))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(131)\n",
    "plt.imshow(i1)\n",
    "plt.subplot(132)\n",
    "plt.imshow(i2)\n",
    "plt.subplot(133)\n",
    "plt.imshow(i3)\n",
    "\n",
    "print(i1.shape,i2.shape,i3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image file path from its id and type   \n",
    "    \"\"\"\n",
    "    if image_type == \"Type_1\" or \\\n",
    "        image_type == \"Type_2\" or \\\n",
    "        image_type == \"Type_3\":\n",
    "        data_path = os.path.join(TRAIN_DATA, image_type)\n",
    "    elif image_type == \"Test\":\n",
    "        data_path = TEST_DATA\n",
    "    elif image_type == \"AType_1\" or \\\n",
    "          image_type == \"AType_2\" or \\\n",
    "          image_type == \"AType_3\":\n",
    "        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n",
    "    else:\n",
    "        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n",
    "\n",
    "    ext = 'jpg'\n",
    "    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n",
    "\n",
    "def get_image_data(image_id, image_type):\n",
    "    \"\"\"\n",
    "    Method to get image data as np.array specifying image id and type\n",
    "    \"\"\"\n",
    "    fname = get_filename(image_id, image_type)\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxHist(hist):\n",
    "    maxArea = (0, 0, 0)\n",
    "    height = []\n",
    "    position = []\n",
    "    for i in range(len(hist)):\n",
    "        if (len(height) == 0):\n",
    "            if (hist[i] > 0):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "        else: \n",
    "            if (hist[i] > height[-1]):\n",
    "                height.append(hist[i])\n",
    "                position.append(i)\n",
    "            elif (hist[i] < height[-1]):\n",
    "                while (height[-1] > hist[i]):\n",
    "                    maxHeight = height.pop()\n",
    "                    area = maxHeight * (i-position[-1])\n",
    "                    if (area > maxArea[0]):\n",
    "                        maxArea = (area, position[-1], i)\n",
    "                    last_position = position.pop()\n",
    "                    if (len(height) == 0):\n",
    "                        break\n",
    "                position.append(last_position)\n",
    "                if (len(height) == 0):\n",
    "                    height.append(hist[i])\n",
    "                elif(height[-1] < hist[i]):\n",
    "                    height.append(hist[i])\n",
    "                else:\n",
    "                    position.pop()    \n",
    "    while (len(height) > 0):\n",
    "        maxHeight = height.pop()\n",
    "        last_position = position.pop()\n",
    "        area =  maxHeight * (len(hist) - last_position)\n",
    "        if (area > maxArea[0]):\n",
    "            maxArea = (area, len(hist), last_position)\n",
    "    return maxArea\n",
    "            \n",
    "\n",
    "def maxRect(img):\n",
    "    maxArea = (0, 0, 0)\n",
    "    addMat = np.zeros(img.shape)\n",
    "    for r in range(img.shape[0]):\n",
    "        if r == 0:\n",
    "            addMat[r] = img[r]\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "        else:\n",
    "            addMat[r] = img[r] + addMat[r-1]\n",
    "            addMat[r][img[r] == 0] *= 0\n",
    "            area = maxHist(addMat[r])\n",
    "            if area[0] > maxArea[0]:\n",
    "                maxArea = area + (r,)\n",
    "    return (int(maxArea[3]+1-maxArea[0]/abs(maxArea[1]-maxArea[2])), maxArea[2], maxArea[3], maxArea[1], maxArea[0])\n",
    "\n",
    "def cropCircle(img):\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    img = cv2.resize(img, dsize=tile_size)\n",
    "            \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY);\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    _, contours, _ = cv2.findContours(thresh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    main_contour = sorted(contours, key = cv2.contourArea, reverse = True)[0]\n",
    "            \n",
    "    ff = np.zeros((gray.shape[0],gray.shape[1]), 'uint8') \n",
    "    cv2.drawContours(ff, main_contour, -1, 1, 15)\n",
    "    ff_mask = np.zeros((gray.shape[0]+2,gray.shape[1]+2), 'uint8')\n",
    "    cv2.floodFill(ff, ff_mask, (int(gray.shape[1]/2), int(gray.shape[0]/2)), 1)\n",
    "    \n",
    "    rect = maxRect(ff)\n",
    "    rectangle = [min(rect[0],rect[2]), max(rect[0],rect[2]), min(rect[1],rect[3]), max(rect[1],rect[3])]\n",
    "    img_crop = img[rectangle[0]:rectangle[1], rectangle[2]:rectangle[3]]\n",
    "    cv2.rectangle(ff,(min(rect[1],rect[3]),min(rect[0],rect[2])),(max(rect[1],rect[3]),max(rect[0],rect[2])),3,2)\n",
    "    \n",
    "    return [img_crop, rectangle, tile_size]\n",
    "\n",
    "def Ra_space(img, Ra_ratio, a_threshold):\n",
    "    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    Ra = np.zeros((w*h, 2))\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            R = math.sqrt((w/2-i)*(w/2-i) + (h/2-j)*(h/2-j))\n",
    "            Ra[i*h+j, 0] = R\n",
    "            Ra[i*h+j, 1] = min(imgLab[i][j][1], a_threshold)\n",
    "            \n",
    "    Ra[:,0] /= max(Ra[:,0])\n",
    "    Ra[:,0] *= Ra_ratio\n",
    "    Ra[:,1] /= max(Ra[:,1])\n",
    "\n",
    "    return Ra\n",
    "\n",
    "def get_and_crop_image(image_id, image_type):\n",
    "    img = get_image_data(image_id, image_type)\n",
    "    initial_shape = img.shape\n",
    "    [img, rectangle_cropCircle, tile_size] = cropCircle(img)\n",
    "    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n",
    "    w = img.shape[0]\n",
    "    h = img.shape[1]\n",
    "    Ra = Ra_space(imgLab, 1.0, 150)\n",
    "    a_channel = np.reshape(Ra[:,1], (w,h))\n",
    "    \n",
    "    g = mixture.GaussianMixture(n_components = 2, covariance_type = 'diag', random_state = 0, init_params = 'kmeans')\n",
    "    image_array_sample = shuffle(Ra, random_state=0)[:1000]\n",
    "    g.fit(image_array_sample)\n",
    "    labels = g.predict(Ra)\n",
    "    labels += 1 # Add 1 to avoid labeling as 0 since regionprops ignores the 0-label.\n",
    "    \n",
    "    # The cluster that has the highest a-mean is selected.\n",
    "    labels_2D = np.reshape(labels, (w,h))\n",
    "    gg_labels_regions = measure.regionprops(labels_2D, intensity_image = a_channel)\n",
    "    gg_intensity = [prop.mean_intensity for prop in gg_labels_regions]\n",
    "    cervix_cluster = gg_intensity.index(max(gg_intensity)) + 1\n",
    "\n",
    "    mask = np.zeros((w * h,1),'uint8')\n",
    "    mask[labels==cervix_cluster] = 255\n",
    "    mask_2D = np.reshape(mask, (w,h))\n",
    "\n",
    "    cc_labels = measure.label(mask_2D, background=0)\n",
    "    regions = measure.regionprops(cc_labels)\n",
    "    areas = [prop.area for prop in regions]\n",
    "\n",
    "    regions_label = [prop.label for prop in regions]\n",
    "    largestCC_label = regions_label[areas.index(max(areas))]\n",
    "    mask_largestCC = np.zeros((w,h),'uint8')\n",
    "    mask_largestCC[cc_labels==largestCC_label] = 255\n",
    "\n",
    "    img_masked = img.copy()\n",
    "    img_masked[mask_largestCC==0] = (0,0,0)\n",
    "    img_masked_gray = cv2.cvtColor(img_masked, cv2.COLOR_RGB2GRAY);\n",
    "            \n",
    "    _,thresh_mask = cv2.threshold(img_masked_gray,0,255,0)\n",
    "            \n",
    "    kernel = np.ones((11,11), np.uint8)\n",
    "    thresh_mask = cv2.dilate(thresh_mask, kernel, iterations = 1)\n",
    "    thresh_mask = cv2.erode(thresh_mask, kernel, iterations = 2)\n",
    "    _, contours_mask, _ = cv2.findContours(thresh_mask.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    main_contour = sorted(contours_mask, key = cv2.contourArea, reverse = True)[0]\n",
    "    cv2.drawContours(img, main_contour, -1, 255, 3)\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(main_contour)\n",
    "    \n",
    "    rectangle = [x+rectangle_cropCircle[2],\n",
    "                 y+rectangle_cropCircle[0],\n",
    "                 w,\n",
    "                 h,\n",
    "                 initial_shape[0],\n",
    "                 initial_shape[1],\n",
    "                 tile_size[0],\n",
    "                 tile_size[1]]\n",
    "\n",
    "    return [image_id, img, rectangle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_image_cropping(image_ids):\n",
    "    out = open('rectangles.csv', \"w\")\n",
    "    out.write(\"image_id,type,x,y,w,h,img_shp_0_init,img_shape1_init,img_shp_0,img_shp_1\\n\")\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    for cur_type in enumerate(types):\n",
    "        partial_get_and_crop = partial(get_and_crop_image, image_type = cur_type[1])    \n",
    "        ret = p.map(partial_get_and_crop, image_ids[cur_type[0]])\n",
    "        for i in range(len(ret)):\n",
    "            out.write(image_ids[type[0]][i])\n",
    "            out.write(',' + str(type[1]))\n",
    "            out.write(',' + str(ret[i][2][0]))\n",
    "            out.write(',' + str(ret[i][2][1]))\n",
    "            out.write(',' + str(ret[i][2][2]))\n",
    "            out.write(',' + str(ret[i][2][3]))\n",
    "            out.write(',' + str(ret[i][2][4]))\n",
    "            out.write(',' + str(ret[i][2][5]))\n",
    "            out.write(',' + str(ret[i][2][6]))\n",
    "            out.write(',' + str(ret[i][2][7]))\n",
    "            out.write('\\n')\n",
    "            img = get_image_data(image_ids[type[0]][i], type[1])\n",
    "            if(img.shape[0] > img.shape[1]):\n",
    "                tile_size = (int(img.shape[1]*256/img.shape[0]), 256)\n",
    "            else:\n",
    "                tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "            img = cv2.resize(img, dsize=tile_size)\n",
    "            cv2.rectangle(img,\n",
    "                          (ret[i][2][0], ret[i][2][1]), \n",
    "                          (ret[i][2][0]+ret[i][2][2], ret[i][2][1]+ret[i][2][3]),\n",
    "                          255,\n",
    "                          2)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "        ret = []\n",
    "    out.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/data/colposcopy/colposcopy/train_stg2/Type_2/2845.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_1/5893.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_2/5892.jpg']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset,Sampler\n",
    "from torchvision import datasets,transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"/home/shiyi/gpu/gpu/\")\n",
    "sys.path.append(\"/home/shiyi/colposcopy/colposcopy/util\")\n",
    "img_dir = \"/data/colposcopy/colposcopy\"\n",
    "\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "corrupt_set  = set()\n",
    "types = [1,2,3]\n",
    "error = glob(os.path.join(img_dir,\"train*\",\"*\",\"2845.jpg\"))+ \\\n",
    "    glob(os.path.join(img_dir,\"train*\",\"*\",\"5893.jpg\"))+glob(os.path.join(img_dir,\"train*\",\"*\",\"5892.jpg\"))\n",
    "print(error)\n",
    "\n",
    "type_1_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_1\",\"*.jpg\")) if i not in error]\n",
    "type_2_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_2\",\"*.jpg\")) if i not in error]\n",
    "type_3_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_3\",\"*.jpg\")) if i not in error]\n",
    "\n",
    "type_data_train = [type_1_train,type_2_train,type_3_train]\n",
    "\n",
    "img_test   = glob(os.path.join(img_dir,\"test\",\"*.jpg\"))\n",
    "img_test_wo_answer = glob(os.path.join(img_dir,\"test_stg2\",\"*.jpg\"))\n",
    "test_path = os.path.join(img_dir,\"solution_stg1_release.csv\")\n",
    "\n",
    "def get_dict(file_path,imgs):\n",
    "    cur_dict = {}\n",
    "    f = open(file_path)\n",
    "    cont = f.readlines()[1:]\n",
    "    for i in range(len(cont)):\n",
    "        line = cont[i].rstrip('\\n')\n",
    "        cur_dict[i] = line.split(',').index('1')\n",
    "    f.close()\n",
    "    return cur_dict \n",
    "\n",
    "def collate_fn1(batch):\n",
    "    x = [item[0] for item in batch if item[0] is not None]\n",
    "    y = [item[1] for item in batch if item[0] is not None]\n",
    "    return x,y\n",
    "\n",
    "def sp_remove(img):\n",
    "    r_c = img[:,:,2]\n",
    "    g_c = img[:,:,1]\n",
    "    b_c = img[:,:,0]\n",
    "\n",
    "    _,r_thres = cv2.threshold(r_c, 210, 255, cv2.THRESH_BINARY)\n",
    "    _,g_thres = cv2.threshold(g_c, 208, 255, cv2.THRESH_BINARY)\n",
    "    _,b_thres = cv2.threshold(b_c, 206, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel_dilate = np.ones((18, 18), np.uint8)\n",
    "    mask = cv2.dilate(r_thres & b_thres & g_thres,kernel_dilate)\n",
    "    dst = cv2.inpaint(img,mask,14,cv2.INPAINT_TELEA)\n",
    "    return dst\n",
    "\n",
    "def crop(img):\n",
    "    return img\n",
    "\n",
    "def preprocess(img):\n",
    "    return crop(sp_remove(img))\n",
    "\n",
    "def cvt(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "class ColpoTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.type_dict = get_dict(test_path,img_test)\n",
    "    def __getitem__(self, index):\n",
    "        file_name = img_test[index]\n",
    "        x = cv2.imread(file_name)\n",
    "        if x is None:\n",
    "            return  None,None\n",
    "        #x = preprocess(x)\n",
    "        x =cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "        y =[0,0,0]\n",
    "        y [self.type_dict[index]-1] = 1\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return len(self.type_dict)\n",
    "    \n",
    "class ColpoTrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.Xy = []\n",
    "        for type_index in types:\n",
    "            for img_index in type_data_train[type_index-1]:\n",
    "                self.Xy.append((img_index,type_index))\n",
    "        self.x_data, self.y_data = zip(*self.Xy)\n",
    "        self.x_data = list(self.x_data)\n",
    "        self.y_data = list(self.y_data)\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.x_data[index]\n",
    "        x = cv2.imread(file_name)\n",
    "        if x is None:\n",
    "            return None,None\n",
    "        #x = preprocess(x)\n",
    "        x = cv2.resize(x,(224,224),interpolation=cv2.INTER_CUBIC)\n",
    "        y = [0,0,0]\n",
    "        y[self.y_data[index]-1] = 1\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,inchannel,outchannel,stride=1,shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes=3):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.pre=nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,2,3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        \n",
    "        self.layer1=self._make_layer(64,64,3)\n",
    "        self.layer2=self._make_layer(64,128,4,stride=2)\n",
    "        self.layer3=self._make_layer(128,256,6,stride=2)\n",
    "        self.layer4=self._make_layer(256,512,3,stride=2)\n",
    "        self.fc=nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self,inchannel,outchannel,block_num,stride=1):\n",
    "        shortcut=nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,1,stride,bias=False),\n",
    "            nn.BatchNorm2d(outchannel))\n",
    " \n",
    "        layers=[ ]\n",
    "        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))\n",
    "        \n",
    "        for i in range(1,block_num):\n",
    "            layers.append(ResidualBlock(outchannel,outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.pre(x)\n",
    "        x=self.layer1(x)\n",
    "        x=self.layer2(x)\n",
    "        x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        x=F.avg_pool2d(x,7)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Found 4 GPU(s)', 'only 2 gpu below threshold')\n",
      "Using GPU 1,0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:58<00:00,  1.48s/it]\n",
      "/root/anaconda2/lib/python2.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/root/anaconda2/lib/python2.7/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type ResidualBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044091, Acc: 0.399903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:59<00:00,  1.64s/it]\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043675, Acc: 0.423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:13<00:00,  1.24s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044475, Acc: 0.390161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:56<00:00,  1.95s/it]\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043672, Acc: 0.423828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 514/514 [14:22<00:00,  1.20s/it]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.044469, Acc: 0.390039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:58<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.043669, Acc: 0.423828\n",
      "set([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cuda = 1\n",
    "\n",
    "if cuda:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "    num_gpu = 2\n",
    "    set_gpu(num_gpu)\n",
    "\n",
    "if torch.cuda.is_available() and cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    \n",
    "batch_size_train = 16\n",
    "batch_size_test = 16\n",
    "colpoTrainDataset = ColpoTrainDataset()\n",
    "colpoTestDataset = ColpoTestDataset()\n",
    "\n",
    "train_loader = DataLoader(dataset=colpoTrainDataset,batch_size=batch_size_train,shuffle=True,num_workers = 2,collate_fn = collate_fn1)\n",
    "test_loader = DataLoader(dataset =colpoTestDataset,batch_size=batch_size_test,shuffle=True,num_workers = 2,collate_fn = collate_fn1)\n",
    "net=ResNet()\n",
    "\n",
    "if cuda:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    net = net.cuda()\n",
    "    \n",
    "criterion = nn.MultiLabelSoftMarginLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0\n",
    "    index = 0\n",
    "    total = 0\n",
    "    for batch_x,batch_y in tqdm(train_loader):\n",
    "        #print(batch_x,batch_y)\n",
    "        #print(torch.full((224,224,3), 0))\n",
    "        batch_x = Tensor(batch_x).permute([0,3,1,2])\n",
    "        batch_y = Tensor(batch_y)\n",
    "        total += batch_x.size()[0]\n",
    "        out = net(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        #print(\"out\",out)\n",
    "        pred = torch.max(out,1)[1]\n",
    "        batch_y = torch.topk(batch_y, 1)[1].squeeze(1)\n",
    "        #print(\"pred\",pred,\"batch_y\",batch_y)\n",
    "        train_correct = (pred == batch_y).sum().item()\n",
    "        \n",
    "        #print(train_correct,\"correct of this batch of \", batch_x.size()[0])\n",
    "        train_acc += train_correct\n",
    "    torch.save(net, 'model.pth')    \n",
    "    print('Train Loss: {:.6f}, Acc: {:.6f}'.format(train_loss /total, train_acc/ total))\n",
    "\n",
    "    net.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    total = 0\n",
    "    for batch_x,batch_y in tqdm(test_loader):\n",
    "        batch_x = Tensor(batch_x).permute([0,3,1,2])\n",
    "        batch_y = Tensor(batch_y)\n",
    "        total += batch_x.size()[0]\n",
    "        #batch_x, batch_y = Variable(batch_x, volatile=True), Variable(batch_y, volatile=True)    \n",
    "        out = net(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        eval_loss += loss.item()\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        batch_y = torch.topk(batch_y, 1)[1].squeeze(1)\n",
    "        num_correct = (pred == batch_y).sum().item()\n",
    "        eval_acc += num_correct\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / total, eval_acc / total))\n",
    "print(corrupt_set)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4018/4018 [10:45<00:00,  5.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "!rm /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
    "def test_net(save_file_path, net, img_dirs, transform =None, im_size=224, thresh=0.05):\n",
    "    \n",
    "    net = torch.load('model.pth')\n",
    "    test_all = img_test_wo_answer + img_test\n",
    "    with open(save_file_path,'w') as f:\n",
    "        #f.write(\"image_name,Type_1,Type_2,Type_3\\n\")\n",
    "        for idir in tqdm(test_all):\n",
    "            name = idir.split('/')[-1]\n",
    "            img = cv2.imread(idir)\n",
    "            if img is None:\n",
    "                label_ind = random.randint(0,3)\n",
    "                label_oh = [name,'0.0','0.0','0.0']\n",
    "                label_oh[label_ind] ='1.0'\n",
    "                \n",
    "            else:\n",
    "                if transform != None:\n",
    "                    img = transform(img)\n",
    "                img = cvt(cv2.resize(img,(im_size,im_size),interpolation=cv2.INTER_CUBIC))\n",
    "                x  = Tensor(img).permute([2,0,1]).unsqueeze(0)    \n",
    "                out = net(x)[0]\n",
    "                p = torch.nn.functional.softmax(out, dim=0)\n",
    "                # to calculate loss using probabilities you can do below \n",
    "                #print(p)\n",
    "                label_oh = [name]+map(lambda x: str(x.item()),p)\n",
    "            \n",
    "            label_oh = ','.join(label_oh)+\"\\n\"\n",
    "            #print (label_oh)\n",
    "            f.write(label_oh)\n",
    "\n",
    "test_net(\"/home/shiyi/colposcopy/colposcopy/odoo/submission.csv\", net, img_dir, transform =None, im_size=224, thresh=0.05)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.ipynb  GMM.ipynb  model.pth  README.md  rsa  submission.csv\n",
      "4018 /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
      "[master 32af987] tiredzzz\n",
      " 1 file changed, 1 insertion(+), 16 deletions(-)\n",
      "sy941021\n",
      "Counting objects: 3, done.\n",
      "Delta compression using up to 32 threads.\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 298 bytes | 0 bytes/s, done.\n",
      "Total 3 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
      "To git@github.com:WordBearerYI/odoo.git\n",
      "   4939ef5..32af987  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd /home/shiyi/colposcopy/colposcopy/odoo\n",
    "!ls\n",
    "!wc -l /home/shiyi/colposcopy/colposcopy/odoo/submission.csv\n",
    "\n",
    "!git add .\n",
    "!git commit -m \"tiredzzz\"\n",
    "!git push | echo WordBearerYI | echo sy941021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/shiyi/.kaggle/kaggle.json'\n",
      "  0%|                                                | 0.00/213k [00:00<?, ?B/s]2019-07-05 15:35:32,830 WARNING Retrying (Retry(total=9, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:35:33,893 WARNING Retrying (Retry(total=8, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:35:35,962 WARNING Retrying (Retry(total=7, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:35:40,003 WARNING Retrying (Retry(total=6, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:35:48,056 WARNING Retrying (Retry(total=5, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:36:04,113 WARNING Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:36:36,223 WARNING Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n",
      "2019-07-05 15:38:40,867 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: SysCallError(-1, 'Unexpected EOF')\",),)': /upload/storage/v1/b/kaggle-competitions-submissions/o?uploadType=resumable&upload_id=AEnB2Up4jMp1ouHdhVoqHWmsDFxpBlTsV_4sST4g8AhL4RnJYNwquVf_F5m5iH5FcRDo_HArzJg2apAeB11AnhYMzOxwbDGcvLfy_f6c3HpkEVE2d-QGUEA\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c intel-mobileodt-cervical-cancer-screening -f /home/shiyi/colposcopy/colposcopy/odoo/submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
