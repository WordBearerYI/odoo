{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/data/colposcopy/colposcopy/train_stg2/Type_2/2845.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_1/5893.jpg', u'/data/colposcopy/colposcopy/train_stg2/Type_2/5892.jpg']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset,Sampler\n",
    "from torchvision import datasets,transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import functional as F\n",
    "\n",
    "sys.path.append(\"/home/shiyi/gpu/gpu/\")\n",
    "sys.path.append(\"/home/shiyi/colposcopy/colposcopy/util\")\n",
    "img_dir = \"/data/colposcopy/colposcopy\"\n",
    "img_dir_target = \"/data/colposcopy/colposcopy_1\"\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "\n",
    "\n",
    "error = glob(os.path.join(img_dir,\"train*\",\"*\",\"2845.jpg\"))+ \\\n",
    "    glob(os.path.join(img_dir,\"train*\",\"*\",\"5893.jpg\"))+glob(os.path.join(img_dir,\"train*\",\"*\",\"5892.jpg\"))\n",
    "print(error)\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "corrupt_set  = set()\n",
    "types = [1,2,3]\n",
    "\n",
    "type_1_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_1\",\"*.jpg\")) if i not in error]\n",
    "type_2_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_2\",\"*.jpg\")) if i not in error]\n",
    "type_3_train = [i for i in glob(os.path.join(img_dir,\"train*\",\"Type_3\",\"*.jpg\")) if i not in error]\n",
    "\n",
    "img_test   = glob(os.path.join(img_dir,\"test\",\"*.jpg\"))\n",
    "img_test_wo_answer = glob(os.path.join(img_dir,\"test_stg2\",\"*.jpg\"))\n",
    "\n",
    "img_paths = type_1_train+type_2_train+type_3_train+img_test+img_test_wo_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColpoProcessDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        path = img_paths[index]\n",
    "        x = cv2.imread(path)\n",
    "        if x is None:\n",
    "            return  None,None\n",
    "        return x\n",
    "    def __len__(self):\n",
    "        return len(img_paths)\n",
    "    \n",
    "def cvt(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def preprocess(img): \n",
    "    r_c = img[:,:,2]\n",
    "    g_c = img[:,:,1]\n",
    "    b_c = img[:,:,0]\n",
    "    _,r_thres = cv2.threshold(r_c, 210, 255, cv2.THRESH_BINARY)\n",
    "    _,g_thres = cv2.threshold(g_c, 208, 255, cv2.THRESH_BINARY)\n",
    "    _,b_thres = cv2.threshold(b_c, 206, 255, cv2.THRESH_BINARY)\n",
    "    mixed = r_thres & b_thres & g_thres\n",
    "    kernel_dilate = np.ones((18, 18), np.uint8)\n",
    "    mask = cv2.dilate(mixed,kernel_dilate)\n",
    "    dst = cv2.inpaint(img,mask,14,cv2.INPAINT_TELEA)\n",
    "    return cvt(dst)\n",
    "\n",
    "def collate_fn1(batch):\n",
    "    x = [item[0] for item in batch if item[0] is not None]\n",
    "    y = [item[1] for item in batch if item[0] is not None]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'train', u'Type_1', u'732.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(img_paths[0].split('/')[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12230 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/colposcopy/colposcopy_1/train/Type_1/732.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/12230 [00:05<16:59:43,  5.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/colposcopy/colposcopy_1/train/Type_1/764.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 2/12230 [00:49<57:22:49, 16.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/colposcopy/colposcopy_1/train/Type_1/1071.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 3/12230 [00:59<49:46:10, 14.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/colposcopy/colposcopy_1/train/Type_1/298.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-429ec90cd915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMWRITE_JPEG_QUALITY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-312769679203>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mkernel_dilate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_dilate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minpaint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPAINT_TELEA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcvt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_train = 16\n",
    "colpoProcessDataset = ColpoProcessDataset()\n",
    "process_loader = DataLoader(dataset=colpoProcessDataset,batch_size=batch_size_train,shuffle=True,num_workers = 2)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "#num_gpu = 1\n",
    "#set_gpu(num_gpu)\n",
    "    \n",
    "for img_path in tqdm(img_paths):\n",
    "    img_path_target = img_dir_target + '/'+'/'.join(img_path.split('/')[4:])\n",
    "    print(img_path_target)\n",
    "    img = cv2.imread(img_path)\n",
    "    x = preprocess(img)\n",
    "    cv2.imwrite(img_path_target,x,[int(cv2.IMWRITE_JPEG_QUALITY),100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
